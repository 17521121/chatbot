{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"phobert.ipynb","provenance":[{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1596682642786}],"collapsed_sections":["r050vPKJ1RRY"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d1ecbb923bb54640ac22e1a0490a9b3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4a817cc70acf4c008cf69c60fdb74384","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5d98e6890e64159971d31c389540c76","IPY_MODEL_c065ec1ee4564e298601225d1e2b081c"]}},"4a817cc70acf4c008cf69c60fdb74384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5d98e6890e64159971d31c389540c76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_51bc11e3a52b44bc9186f8e761be8a4b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":895321,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":895321,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_813da716bdb544b2a28612b130adf4b7"}},"c065ec1ee4564e298601225d1e2b081c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_32ad76524c3840c58d91f693d7c02796","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 895k/895k [00:00&lt;00:00, 2.26MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac6a93193010489eaec5009bc9843124"}},"51bc11e3a52b44bc9186f8e761be8a4b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"813da716bdb544b2a28612b130adf4b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32ad76524c3840c58d91f693d7c02796":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ac6a93193010489eaec5009bc9843124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8489de7cf704a0997b12cbe56685222":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_53374f12768f499aab6205c269eede12","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c2c580d5d9c5432b8732ddb8ee5fc979","IPY_MODEL_66f9fecfc7d5402e9dbbd512efdfad06"]}},"53374f12768f499aab6205c269eede12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c2c580d5d9c5432b8732ddb8ee5fc979":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_953c9b09474d4b769df3da54752bea65","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1135173,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1135173,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e06dec3d114f498483628ec44ee0c563"}},"66f9fecfc7d5402e9dbbd512efdfad06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8c353bd2d3448f4bb1d91b8cb1fdb22","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.14M/1.14M [00:00&lt;00:00, 6.37MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_501d8315109d4d169bed1c54c37b99bd"}},"953c9b09474d4b769df3da54752bea65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e06dec3d114f498483628ec44ee0c563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8c353bd2d3448f4bb1d91b8cb1fdb22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"501d8315109d4d169bed1c54c37b99bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UTpitzzYvYQQ"},"source":["# Initialization"]},{"cell_type":"code","metadata":{"id":"4enR4ml-vcGJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425233846,"user_tz":-420,"elapsed":19076,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"f27763e8-b3b4-4c3d-fa2f-fb61437c5320"},"source":["from google.colab import drive\n","drive.mount(\"drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iK7IHJoYvcj9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425249098,"user_tz":-420,"elapsed":23026,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"4d89ba15-8a68-4042-f6e0-c14495080ac8"},"source":["!pip install transformers==4.0.0 vncorenlp fairseq==0.10.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==4.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 5.7MB/s \n","\u001b[?25hCollecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 19.4MB/s \n","\u001b[?25hCollecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/da/7c7032988dade3b21ccfd5b226e50b382abfd3459129d67240bb004506ae/fairseq-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (1.7MB)\n","\u001b[K     |████████████████████████████████| 1.7MB 29.6MB/s \n","\u001b[?25hCollecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.3MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 47.4MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (20.8)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.0) (1.19.4)\n","Collecting hydra-core\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/1f/7f502b9e37596164111655861370b08626f46f9e4524433c354f472765d4/hydra_core-1.0.4-py3-none-any.whl (122kB)\n","\u001b[K     |████████████████████████████████| 122kB 12.2MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.7.0+cu101)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.4)\n","Collecting sacrebleu>=1.4.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.0) (1.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.0) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.0) (2.4.7)\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 51.5MB/s \n","\u001b[?25hCollecting omegaconf>=2.0.5\n","  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n","Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->fairseq) (3.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (3.7.4.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Collecting PyYAML>=5.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n","\u001b[K     |████████████████████████████████| 276kB 46.2MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->fairseq) (3.4.0)\n","Building wheels for collected packages: vncorenlp, sacremoses, antlr4-python3-runtime, PyYAML\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645936 sha256=f9cbfae8748a97151c3af0fedf0558dc88a54caa22edbe0b2151c71daab42bbc\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c3aa43f7638f418470a35f7a66082481f1ce3177c790d3dc8db613025f49546a\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141231 sha256=90e0312d7f38011a8e479308e16fa812809fbe7680fd0e75ac0634f6b04feb21\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=5b8e1a4b176df4d6145929a35191391f55622aae969d4cc84b7f8d23bf3c048c\n","  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n","Successfully built vncorenlp sacremoses antlr4-python3-runtime PyYAML\n","Installing collected packages: tokenizers, sacremoses, transformers, vncorenlp, antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, portalocker, sacrebleu, fairseq\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.3.1 antlr4-python3-runtime-4.8 fairseq-0.10.1 hydra-core-1.0.4 omegaconf-2.0.5 portalocker-2.0.0 sacrebleu-1.4.14 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0 vncorenlp-1.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J4abH6L1vtH7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425253168,"user_tz":-420,"elapsed":704,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"7f79784d-8de3-4054-9516-f1b1c0fead56"},"source":["%cd drive/My Drive/Colab Notebooks/chatbot"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/chatbot\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zjnGKvEowNEp","colab":{"base_uri":"https://localhost:8080/","height":132,"referenced_widgets":["d1ecbb923bb54640ac22e1a0490a9b3e","4a817cc70acf4c008cf69c60fdb74384","a5d98e6890e64159971d31c389540c76","c065ec1ee4564e298601225d1e2b081c","51bc11e3a52b44bc9186f8e761be8a4b","813da716bdb544b2a28612b130adf4b7","32ad76524c3840c58d91f693d7c02796","ac6a93193010489eaec5009bc9843124","a8489de7cf704a0997b12cbe56685222","53374f12768f499aab6205c269eede12","c2c580d5d9c5432b8732ddb8ee5fc979","66f9fecfc7d5402e9dbbd512efdfad06","953c9b09474d4b769df3da54752bea65","e06dec3d114f498483628ec44ee0c563","e8c353bd2d3448f4bb1d91b8cb1fdb22","501d8315109d4d169bed1c54c37b99bd"]},"executionInfo":{"status":"ok","timestamp":1609425271017,"user_tz":-420,"elapsed":17250,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"0d918609-d3d6-4ade-a522-013c09d6254e"},"source":["from model import Net\n","from data_loader import *\n","from functions import *"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1ecbb923bb54640ac22e1a0490a9b3e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895321.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8489de7cf704a0997b12cbe56685222","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1135173.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ma0IfG7MwRLv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425271019,"user_tz":-420,"elapsed":15053,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"f5157b41-c105-4700-abf3-5932fbd0335f"},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","max_tokens_length = 256\n"," \n","class Args():\n","  def __init__(self):\n","    self.max_turn = 2\n","    self.over_sample = False # turn 1 + turn 2\n","    self.normalize = True   # True: target = dot - norm | False: target = dot product\n","    self.prepend = True    # emo prepend\n","    self.stop_crit_num_epochs = 3 # early stop\n","    self.learning_rate = 1e-5\n","    self.epochs = 30\n","    self.hits_at_nb_cands = 100 # p@1,100\n","    self.display_iter = 100 # help=\"Frequency of train logging\"\n","    self.batch_size = 32\n","    self.optimizer = \"adamax\"\n","    self.train = False  # Train or evaluate\n","    self.log_file = \"logs/phobert_prepend_normalize_finetune_bosung.txt\"\n","    self.model_file = \"models/phobert_prepend_normalize_finetune_bosung.pt\"\n","\n","option = Args()\n","logger = get_logger(option)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12/31/2020 02:34:30 PM: [ CONFIG:\n","{\n","    \"batch_size\": 32,\n","    \"display_iter\": 100,\n","    \"epochs\": 30,\n","    \"hits_at_nb_cands\": 100,\n","    \"learning_rate\": 1e-05,\n","    \"log_file\": \"logs/phobert_prepend_normalize_finetune_bosung.txt\",\n","    \"max_turn\": 2,\n","    \"model_file\": \"models/phobert_prepend_normalize_finetune_bosung.pt\",\n","    \"normalize\": true,\n","    \"optimizer\": \"adamax\",\n","    \"over_sample\": false,\n","    \"prepend\": true,\n","    \"stop_crit_num_epochs\": 3,\n","    \"train\": false\n","} ]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"X9q2YiXSv8wf"},"source":["# Load dataset"]},{"cell_type":"code","metadata":{"id":"JPpOEHfBwT5X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425376231,"user_tz":-420,"elapsed":76489,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"a43fea5c-f4de-4a3d-c3aa-820c12f1f1e2"},"source":["train_dataset = EmpDataset(\n","  \"ED/train_manual - bosung\",\n","#   \"ED/train_manual\",\n","#   \"ED/train_auto\",\n","#   \"ED/train_manual_compound\",\n","  maxlen = max_tokens_length,\n","  history_len = option.max_turn,\n","  prepend = option.prepend,\n","  over_sample = option.train and option.over_sample\n",")\n","\n","train_iter = DataLoader(\n","  dataset     = train_dataset,\n","  batch_size  = option.batch_size,\n","  shuffle     = option.train,\n","  num_workers = 0,\n","  collate_fn  = batchify,\n","  pin_memory  = True,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 87%|████████▋ | 21121/24295 [01:05<00:09, 348.97it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (277 > 256). Running this sequence through the model will result in indexing errors\n","100%|██████████| 24295/24295 [01:15<00:00, 322.71it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NslOnSzrjWcI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609341083900,"user_tz":-420,"elapsed":86827,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"683a1779-48b4-4466-f85c-d600c83facc4"},"source":["dev_dataset = EmpDataset(\n","#   \"ED/valid_auto\",\n","  \"ED/valid_manual\",\n","#   \"ED/valid_manual_compound\",\n","  maxlen = max_tokens_length,\n","  history_len = option.max_turn,\n","  prepend = option.prepend,\n","  over_sample = option.train and option.over_sample\n",")\n","\n","dev_iter = DataLoader(\n","  dataset     = dev_dataset,\n","  batch_size  = option.batch_size,\n","  shuffle     = option.train,\n","  num_workers = 0,\n","  collate_fn  = batchify,\n","  pin_memory  = True,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 2496/2496 [00:07<00:00, 325.35it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"xm1Kwo1QwUg3"},"source":["torch.save(train_iter,\"torch_pre_load/train_manual_noprepend.pth\")\n","# torch.save(dev_iter,\"torch_pre_load/dev_manual.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Bmj9f5EwWB3"},"source":["train_iter = torch.load(\"torch_pre_load/train_auto.pth\")\n","# dev_iter = torch.load(\"torch_pre_load/dev_auto.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9II3kAYwjFB"},"source":["# Train"]},{"cell_type":"code","metadata":{"id":"CPVBll9lwk0v"},"source":["net = Net(device)\n","\n","if device == \"cuda\":\n","  torch.cuda.set_device(-1) # get the lastest device (GPU)\n","  net = torch.nn.DataParallel(net)\n","  net.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iR_xqf1v-oJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609345825944,"user_tz":-420,"elapsed":4826400,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"e864908a-b2c1-406d-b73b-2e95de307b63"},"source":["###############\n","### Train #####\n","###############\n","    \n","if option.optimizer == \"adamax\":\n","    lr = option.learning_rate\n","    named_params_to_optimize = filter(\n","        lambda p: p[1].requires_grad, net.named_parameters()\n","    )\n","    params_to_optimize = (p[1] for p in named_params_to_optimize)\n","    optimizer = optim.Adamax(params_to_optimize, lr=lr)\n","\n","    \n","start_time = time.time()\n","#best_loss = float(\"+inf\")\n","\n","with torch.no_grad():\n","    best_loss = validate(\n","        0,\n","        net,\n","        dev_iter,\n","        nb_candidates=option.hits_at_nb_cands,\n","        normalize = option.normalize\n","    )\n","\n"," \n","for epoch in range(0, option.epochs):\n","    train(epoch, start_time, net, optimizer, option, train_iter, normalize = option.normalize)\n","    with torch.no_grad():\n","        loss = validate(\n","            epoch,\n","            net,\n","            dev_iter,\n","            nb_candidates=option.hits_at_nb_cands,\n","            normalize = option.normalize\n","        )\n","        if loss < best_loss:\n","            best_loss = loss\n","            best_loss_epoch = epoch\n","            logging.info(f\"New best loss, saving model to {option.model_file}\")\n","            torch.save(net.state_dict(), f\"{option.model_file}\")\n","        # Stop if it's been too many epochs since the loss has decreased\n","        if option.stop_crit_num_epochs != -1:\n","            if epoch - best_loss_epoch >= option.stop_crit_num_epochs:\n","                break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12/30/2020 03:11:37 PM: [ Processing candidate top-K ]\n","12/30/2020 03:11:37 PM: [ Valid (shuffled): Epoch = 0 | avg loss = 5.365 | batch P@1 = 3.94 % | P@1,100 = 1.36% | P@3,100 = 4.36% | P@10,100 = 13.73% | valid time = 5.13 (s) ]\n","12/30/2020 03:12:26 PM: [ train: Epoch = 0 | iter = 100/363 | loss = 3.616 | batch P@1 = 4.44 % | elapsed time = 54.90 (s) ]\n","12/30/2020 03:13:17 PM: [ train: Epoch = 0 | iter = 200/363 | loss = 3.369 | batch P@1 = 6.52 % | elapsed time = 105.74 (s) ]\n","12/30/2020 03:14:08 PM: [ train: Epoch = 0 | iter = 300/363 | loss = 2.592 | batch P@1 = 15.03 % | elapsed time = 156.95 (s) ]\n","12/30/2020 03:14:40 PM: [ train: Epoch = 0 | iter = 363/363 | loss = 2.354 | batch P@1 = 19.02 % | elapsed time = 188.27 (s) ]\n","12/30/2020 03:14:40 PM: [ train: Epoch 0 done. Time for epoch = 183.06 (s) ]\n","12/30/2020 03:14:45 PM: [ Processing candidate top-K ]\n","12/30/2020 03:14:45 PM: [ Valid (shuffled): Epoch = 0 | avg loss = 2.472 | batch P@1 = 33.33 % | P@1,100 = 20.45% | P@3,100 = 35.36% | P@10,100 = 55.91% | valid time = 5.08 (s) ]\n","12/30/2020 03:14:45 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:15:38 PM: [ train: Epoch = 1 | iter = 100/363 | loss = 2.282 | batch P@1 = 37.94 % | elapsed time = 246.08 (s) ]\n","12/30/2020 03:16:28 PM: [ train: Epoch = 1 | iter = 200/363 | loss = 2.220 | batch P@1 = 39.30 % | elapsed time = 296.19 (s) ]\n","12/30/2020 03:17:18 PM: [ train: Epoch = 1 | iter = 300/363 | loss = 2.142 | batch P@1 = 40.03 % | elapsed time = 346.89 (s) ]\n","12/30/2020 03:17:50 PM: [ train: Epoch = 1 | iter = 363/363 | loss = 2.100 | batch P@1 = 40.50 % | elapsed time = 378.18 (s) ]\n","12/30/2020 03:17:50 PM: [ train: Epoch 1 done. Time for epoch = 182.08 (s) ]\n","12/30/2020 03:17:55 PM: [ Processing candidate top-K ]\n","12/30/2020 03:17:55 PM: [ Valid (shuffled): Epoch = 1 | avg loss = 2.381 | batch P@1 = 34.79 % | P@1,100 = 22.36% | P@3,100 = 37.27% | P@10,100 = 59.45% | valid time = 5.14 (s) ]\n","12/30/2020 03:17:55 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:18:46 PM: [ train: Epoch = 2 | iter = 100/363 | loss = 2.070 | batch P@1 = 43.28 % | elapsed time = 434.93 (s) ]\n","12/30/2020 03:19:35 PM: [ train: Epoch = 2 | iter = 200/363 | loss = 1.976 | batch P@1 = 44.42 % | elapsed time = 483.17 (s) ]\n","12/30/2020 03:20:25 PM: [ train: Epoch = 2 | iter = 300/363 | loss = 1.971 | batch P@1 = 45.04 % | elapsed time = 533.36 (s) ]\n","12/30/2020 03:20:58 PM: [ train: Epoch = 2 | iter = 363/363 | loss = 1.936 | batch P@1 = 44.98 % | elapsed time = 566.64 (s) ]\n","12/30/2020 03:20:58 PM: [ train: Epoch 2 done. Time for epoch = 180.69 (s) ]\n","12/30/2020 03:21:03 PM: [ Processing candidate top-K ]\n","12/30/2020 03:21:03 PM: [ Valid (shuffled): Epoch = 2 | avg loss = 1.921 | batch P@1 = 48.50 % | P@1,100 = 31.09% | P@3,100 = 51.45% | P@10,100 = 71.73% | valid time = 5.05 (s) ]\n","12/30/2020 03:21:03 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:21:56 PM: [ train: Epoch = 3 | iter = 100/363 | loss = 1.878 | batch P@1 = 47.97 % | elapsed time = 624.28 (s) ]\n","12/30/2020 03:22:46 PM: [ train: Epoch = 3 | iter = 200/363 | loss = 1.848 | batch P@1 = 47.73 % | elapsed time = 674.94 (s) ]\n","12/30/2020 03:23:38 PM: [ train: Epoch = 3 | iter = 300/363 | loss = 1.858 | batch P@1 = 47.86 % | elapsed time = 726.11 (s) ]\n","12/30/2020 03:24:08 PM: [ train: Epoch = 3 | iter = 363/363 | loss = 1.861 | batch P@1 = 47.85 % | elapsed time = 756.59 (s) ]\n","12/30/2020 03:24:08 PM: [ train: Epoch 3 done. Time for epoch = 182.34 (s) ]\n","12/30/2020 03:24:13 PM: [ Processing candidate top-K ]\n","12/30/2020 03:24:13 PM: [ Valid (shuffled): Epoch = 3 | avg loss = 1.847 | batch P@1 = 49.53 % | P@1,100 = 33.64% | P@3,100 = 52.55% | P@10,100 = 71.91% | valid time = 4.99 (s) ]\n","12/30/2020 03:24:13 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:25:07 PM: [ train: Epoch = 4 | iter = 100/363 | loss = 1.827 | batch P@1 = 49.06 % | elapsed time = 815.06 (s) ]\n","12/30/2020 03:25:59 PM: [ train: Epoch = 4 | iter = 200/363 | loss = 1.743 | batch P@1 = 49.66 % | elapsed time = 867.40 (s) ]\n","12/30/2020 03:26:47 PM: [ train: Epoch = 4 | iter = 300/363 | loss = 1.760 | batch P@1 = 50.06 % | elapsed time = 915.61 (s) ]\n","12/30/2020 03:27:17 PM: [ train: Epoch = 4 | iter = 363/363 | loss = 1.737 | batch P@1 = 50.02 % | elapsed time = 945.92 (s) ]\n","12/30/2020 03:27:17 PM: [ train: Epoch 4 done. Time for epoch = 181.84 (s) ]\n","12/30/2020 03:27:22 PM: [ Processing candidate top-K ]\n","12/30/2020 03:27:23 PM: [ Valid (shuffled): Epoch = 4 | avg loss = 1.816 | batch P@1 = 50.13 % | P@1,100 = 31.82% | P@3,100 = 52.45% | P@10,100 = 74.64% | valid time = 5.10 (s) ]\n","12/30/2020 03:27:23 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:28:15 PM: [ train: Epoch = 5 | iter = 100/363 | loss = 1.653 | batch P@1 = 51.81 % | elapsed time = 1003.56 (s) ]\n","12/30/2020 03:29:07 PM: [ train: Epoch = 5 | iter = 200/363 | loss = 1.707 | batch P@1 = 52.19 % | elapsed time = 1055.50 (s) ]\n","12/30/2020 03:29:56 PM: [ train: Epoch = 5 | iter = 300/363 | loss = 1.699 | batch P@1 = 52.10 % | elapsed time = 1104.94 (s) ]\n","12/30/2020 03:30:27 PM: [ train: Epoch = 5 | iter = 363/363 | loss = 1.734 | batch P@1 = 51.87 % | elapsed time = 1135.11 (s) ]\n","12/30/2020 03:30:27 PM: [ train: Epoch 5 done. Time for epoch = 181.70 (s) ]\n","12/30/2020 03:30:32 PM: [ Processing candidate top-K ]\n","12/30/2020 03:30:32 PM: [ Valid (shuffled): Epoch = 5 | avg loss = 1.755 | batch P@1 = 51.50 % | P@1,100 = 34.73% | P@3,100 = 54.64% | P@10,100 = 74.27% | valid time = 5.04 (s) ]\n","12/30/2020 03:30:32 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:31:25 PM: [ train: Epoch = 6 | iter = 100/363 | loss = 1.615 | batch P@1 = 54.00 % | elapsed time = 1193.80 (s) ]\n","12/30/2020 03:32:15 PM: [ train: Epoch = 6 | iter = 200/363 | loss = 1.614 | batch P@1 = 53.72 % | elapsed time = 1243.29 (s) ]\n","12/30/2020 03:33:05 PM: [ train: Epoch = 6 | iter = 300/363 | loss = 1.615 | batch P@1 = 53.47 % | elapsed time = 1293.39 (s) ]\n","12/30/2020 03:33:36 PM: [ train: Epoch = 6 | iter = 363/363 | loss = 1.610 | batch P@1 = 53.65 % | elapsed time = 1324.81 (s) ]\n","12/30/2020 03:33:36 PM: [ train: Epoch 6 done. Time for epoch = 182.08 (s) ]\n","12/30/2020 03:33:41 PM: [ Processing candidate top-K ]\n","12/30/2020 03:33:41 PM: [ Valid (shuffled): Epoch = 6 | avg loss = 1.756 | batch P@1 = 53.13 % | P@1,100 = 36.55% | P@3,100 = 57.36% | P@10,100 = 76.55% | valid time = 5.16 (s) ]\n","12/30/2020 03:34:33 PM: [ train: Epoch = 7 | iter = 100/363 | loss = 1.534 | batch P@1 = 55.50 % | elapsed time = 1381.20 (s) ]\n","12/30/2020 03:35:23 PM: [ train: Epoch = 7 | iter = 200/363 | loss = 1.548 | batch P@1 = 55.27 % | elapsed time = 1431.25 (s) ]\n","12/30/2020 03:36:12 PM: [ train: Epoch = 7 | iter = 300/363 | loss = 1.518 | batch P@1 = 55.52 % | elapsed time = 1480.50 (s) ]\n","12/30/2020 03:36:44 PM: [ train: Epoch = 7 | iter = 363/363 | loss = 1.576 | batch P@1 = 55.09 % | elapsed time = 1512.23 (s) ]\n","12/30/2020 03:36:44 PM: [ train: Epoch 7 done. Time for epoch = 182.18 (s) ]\n","12/30/2020 03:36:49 PM: [ Processing candidate top-K ]\n","12/30/2020 03:36:49 PM: [ Valid (shuffled): Epoch = 7 | avg loss = 1.746 | batch P@1 = 51.33 % | P@1,100 = 35.91% | P@3,100 = 56.82% | P@10,100 = 75.82% | valid time = 5.10 (s) ]\n","12/30/2020 03:36:49 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:37:41 PM: [ train: Epoch = 8 | iter = 100/363 | loss = 1.475 | batch P@1 = 57.00 % | elapsed time = 1569.28 (s) ]\n","12/30/2020 03:38:30 PM: [ train: Epoch = 8 | iter = 200/363 | loss = 1.439 | batch P@1 = 58.03 % | elapsed time = 1618.90 (s) ]\n","12/30/2020 03:39:21 PM: [ train: Epoch = 8 | iter = 300/363 | loss = 1.511 | batch P@1 = 57.45 % | elapsed time = 1669.90 (s) ]\n","12/30/2020 03:39:53 PM: [ train: Epoch = 8 | iter = 363/363 | loss = 1.452 | batch P@1 = 57.33 % | elapsed time = 1701.97 (s) ]\n","12/30/2020 03:39:53 PM: [ train: Epoch 8 done. Time for epoch = 182.11 (s) ]\n","12/30/2020 03:39:59 PM: [ Processing candidate top-K ]\n","12/30/2020 03:39:59 PM: [ Valid (shuffled): Epoch = 8 | avg loss = 1.695 | batch P@1 = 54.50 % | P@1,100 = 37.55% | P@3,100 = 57.55% | P@10,100 = 77.18% | valid time = 5.12 (s) ]\n","12/30/2020 03:39:59 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:40:51 PM: [ train: Epoch = 9 | iter = 100/363 | loss = 1.434 | batch P@1 = 57.78 % | elapsed time = 1759.32 (s) ]\n","12/30/2020 03:41:40 PM: [ train: Epoch = 9 | iter = 200/363 | loss = 1.433 | batch P@1 = 58.03 % | elapsed time = 1808.45 (s) ]\n","12/30/2020 03:42:31 PM: [ train: Epoch = 9 | iter = 300/363 | loss = 1.391 | batch P@1 = 58.11 % | elapsed time = 1859.68 (s) ]\n","12/30/2020 03:43:04 PM: [ train: Epoch = 9 | iter = 363/363 | loss = 1.409 | batch P@1 = 58.00 % | elapsed time = 1892.74 (s) ]\n","12/30/2020 03:43:04 PM: [ train: Epoch 9 done. Time for epoch = 183.22 (s) ]\n","12/30/2020 03:43:09 PM: [ Processing candidate top-K ]\n","12/30/2020 03:43:09 PM: [ Valid (shuffled): Epoch = 9 | avg loss = 1.723 | batch P@1 = 52.53 % | P@1,100 = 37.82% | P@3,100 = 58.64% | P@10,100 = 78.00% | valid time = 5.06 (s) ]\n","12/30/2020 03:44:00 PM: [ train: Epoch = 10 | iter = 100/363 | loss = 1.372 | batch P@1 = 59.84 % | elapsed time = 1948.13 (s) ]\n","12/30/2020 03:44:51 PM: [ train: Epoch = 10 | iter = 200/363 | loss = 1.351 | batch P@1 = 59.45 % | elapsed time = 1999.66 (s) ]\n","12/30/2020 03:45:42 PM: [ train: Epoch = 10 | iter = 300/363 | loss = 1.345 | batch P@1 = 59.49 % | elapsed time = 2050.10 (s) ]\n","12/30/2020 03:46:12 PM: [ train: Epoch = 10 | iter = 363/363 | loss = 1.363 | batch P@1 = 59.66 % | elapsed time = 2080.40 (s) ]\n","12/30/2020 03:46:12 PM: [ train: Epoch 10 done. Time for epoch = 182.52 (s) ]\n","12/30/2020 03:46:17 PM: [ Processing candidate top-K ]\n","12/30/2020 03:46:17 PM: [ Valid (shuffled): Epoch = 10 | avg loss = 1.663 | batch P@1 = 53.98 % | P@1,100 = 38.36% | P@3,100 = 58.27% | P@10,100 = 78.82% | valid time = 5.10 (s) ]\n","12/30/2020 03:46:17 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:47:11 PM: [ train: Epoch = 11 | iter = 100/363 | loss = 1.302 | batch P@1 = 61.66 % | elapsed time = 2139.53 (s) ]\n","12/30/2020 03:48:00 PM: [ train: Epoch = 11 | iter = 200/363 | loss = 1.299 | batch P@1 = 61.11 % | elapsed time = 2188.85 (s) ]\n","12/30/2020 03:48:50 PM: [ train: Epoch = 11 | iter = 300/363 | loss = 1.298 | batch P@1 = 61.79 % | elapsed time = 2238.98 (s) ]\n","12/30/2020 03:49:21 PM: [ train: Epoch = 11 | iter = 363/363 | loss = 1.272 | batch P@1 = 61.71 % | elapsed time = 2269.58 (s) ]\n","12/30/2020 03:49:21 PM: [ train: Epoch 11 done. Time for epoch = 181.51 (s) ]\n","12/30/2020 03:49:26 PM: [ Processing candidate top-K ]\n","12/30/2020 03:49:26 PM: [ Valid (shuffled): Epoch = 11 | avg loss = 1.668 | batch P@1 = 55.44 % | P@1,100 = 40.45% | P@3,100 = 60.45% | P@10,100 = 79.64% | valid time = 5.02 (s) ]\n","12/30/2020 03:50:16 PM: [ train: Epoch = 12 | iter = 100/363 | loss = 1.231 | batch P@1 = 63.16 % | elapsed time = 2324.49 (s) ]\n","12/30/2020 03:51:07 PM: [ train: Epoch = 12 | iter = 200/363 | loss = 1.247 | batch P@1 = 62.97 % | elapsed time = 2375.79 (s) ]\n","12/30/2020 03:51:56 PM: [ train: Epoch = 12 | iter = 300/363 | loss = 1.211 | batch P@1 = 62.86 % | elapsed time = 2424.61 (s) ]\n","12/30/2020 03:52:28 PM: [ train: Epoch = 12 | iter = 363/363 | loss = 1.191 | batch P@1 = 63.10 % | elapsed time = 2456.45 (s) ]\n","12/30/2020 03:52:28 PM: [ train: Epoch 12 done. Time for epoch = 181.76 (s) ]\n","12/30/2020 03:52:33 PM: [ Processing candidate top-K ]\n","12/30/2020 03:52:33 PM: [ Valid (shuffled): Epoch = 12 | avg loss = 1.613 | batch P@1 = 56.56 % | P@1,100 = 40.36% | P@3,100 = 60.45% | P@10,100 = 79.91% | valid time = 5.05 (s) ]\n","12/30/2020 03:52:33 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:53:26 PM: [ train: Epoch = 13 | iter = 100/363 | loss = 1.154 | batch P@1 = 65.34 % | elapsed time = 2515.05 (s) ]\n","12/30/2020 03:54:18 PM: [ train: Epoch = 13 | iter = 200/363 | loss = 1.192 | batch P@1 = 64.84 % | elapsed time = 2566.43 (s) ]\n","12/30/2020 03:55:06 PM: [ train: Epoch = 13 | iter = 300/363 | loss = 1.187 | batch P@1 = 64.26 % | elapsed time = 2614.72 (s) ]\n","12/30/2020 03:55:37 PM: [ train: Epoch = 13 | iter = 363/363 | loss = 1.154 | batch P@1 = 64.43 % | elapsed time = 2645.80 (s) ]\n","12/30/2020 03:55:37 PM: [ train: Epoch 13 done. Time for epoch = 181.73 (s) ]\n","12/30/2020 03:55:42 PM: [ Processing candidate top-K ]\n","12/30/2020 03:55:42 PM: [ Valid (shuffled): Epoch = 13 | avg loss = 1.582 | batch P@1 = 55.96 % | P@1,100 = 39.91% | P@3,100 = 60.00% | P@10,100 = 80.55% | valid time = 5.11 (s) ]\n","12/30/2020 03:55:42 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:56:35 PM: [ train: Epoch = 14 | iter = 100/363 | loss = 1.110 | batch P@1 = 66.25 % | elapsed time = 2703.29 (s) ]\n","12/30/2020 03:57:26 PM: [ train: Epoch = 14 | iter = 200/363 | loss = 1.105 | batch P@1 = 65.53 % | elapsed time = 2754.12 (s) ]\n","12/30/2020 03:58:16 PM: [ train: Epoch = 14 | iter = 300/363 | loss = 1.105 | batch P@1 = 65.65 % | elapsed time = 2804.82 (s) ]\n","12/30/2020 03:58:47 PM: [ train: Epoch = 14 | iter = 363/363 | loss = 1.071 | batch P@1 = 65.84 % | elapsed time = 2835.70 (s) ]\n","12/30/2020 03:58:47 PM: [ train: Epoch 14 done. Time for epoch = 182.27 (s) ]\n","12/30/2020 03:58:52 PM: [ Processing candidate top-K ]\n","12/30/2020 03:58:52 PM: [ Valid (shuffled): Epoch = 14 | avg loss = 1.581 | batch P@1 = 57.16 % | P@1,100 = 42.45% | P@3,100 = 62.27% | P@10,100 = 79.91% | valid time = 5.13 (s) ]\n","12/30/2020 03:58:52 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 03:59:45 PM: [ train: Epoch = 15 | iter = 100/363 | loss = 1.061 | batch P@1 = 67.59 % | elapsed time = 2893.64 (s) ]\n","12/30/2020 04:00:35 PM: [ train: Epoch = 15 | iter = 200/363 | loss = 1.057 | batch P@1 = 67.44 % | elapsed time = 2943.66 (s) ]\n","12/30/2020 04:01:26 PM: [ train: Epoch = 15 | iter = 300/363 | loss = 1.047 | batch P@1 = 67.48 % | elapsed time = 2994.42 (s) ]\n","12/30/2020 04:01:58 PM: [ train: Epoch = 15 | iter = 363/363 | loss = 1.018 | batch P@1 = 67.69 % | elapsed time = 3026.34 (s) ]\n","12/30/2020 04:01:58 PM: [ train: Epoch 15 done. Time for epoch = 182.96 (s) ]\n","12/30/2020 04:02:03 PM: [ Processing candidate top-K ]\n","12/30/2020 04:02:03 PM: [ Valid (shuffled): Epoch = 15 | avg loss = 1.566 | batch P@1 = 57.67 % | P@1,100 = 40.36% | P@3,100 = 61.45% | P@10,100 = 81.27% | valid time = 5.07 (s) ]\n","12/30/2020 04:02:03 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 04:02:56 PM: [ train: Epoch = 16 | iter = 100/363 | loss = 1.009 | batch P@1 = 68.66 % | elapsed time = 3084.13 (s) ]\n","12/30/2020 04:03:45 PM: [ train: Epoch = 16 | iter = 200/363 | loss = 1.002 | batch P@1 = 68.86 % | elapsed time = 3133.76 (s) ]\n","12/30/2020 04:04:36 PM: [ train: Epoch = 16 | iter = 300/363 | loss = 0.992 | batch P@1 = 69.27 % | elapsed time = 3185.04 (s) ]\n","12/30/2020 04:05:08 PM: [ train: Epoch = 16 | iter = 363/363 | loss = 0.997 | batch P@1 = 69.21 % | elapsed time = 3216.50 (s) ]\n","12/30/2020 04:05:08 PM: [ train: Epoch 16 done. Time for epoch = 182.54 (s) ]\n","12/30/2020 04:05:13 PM: [ Processing candidate top-K ]\n","12/30/2020 04:05:13 PM: [ Valid (shuffled): Epoch = 16 | avg loss = 1.557 | batch P@1 = 58.27 % | P@1,100 = 43.64% | P@3,100 = 63.45% | P@10,100 = 82.64% | valid time = 5.10 (s) ]\n","12/30/2020 04:05:13 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 04:06:07 PM: [ train: Epoch = 17 | iter = 100/363 | loss = 0.906 | batch P@1 = 71.31 % | elapsed time = 3275.80 (s) ]\n","12/30/2020 04:06:58 PM: [ train: Epoch = 17 | iter = 200/363 | loss = 0.925 | batch P@1 = 71.28 % | elapsed time = 3326.89 (s) ]\n","12/30/2020 04:07:47 PM: [ train: Epoch = 17 | iter = 300/363 | loss = 0.927 | batch P@1 = 71.05 % | elapsed time = 3375.88 (s) ]\n","12/30/2020 04:08:19 PM: [ train: Epoch = 17 | iter = 363/363 | loss = 0.950 | batch P@1 = 71.09 % | elapsed time = 3407.19 (s) ]\n","12/30/2020 04:08:19 PM: [ train: Epoch 17 done. Time for epoch = 183.06 (s) ]\n","12/30/2020 04:08:24 PM: [ Processing candidate top-K ]\n","12/30/2020 04:08:24 PM: [ Valid (shuffled): Epoch = 17 | avg loss = 1.514 | batch P@1 = 58.44 % | P@1,100 = 41.55% | P@3,100 = 62.82% | P@10,100 = 84.64% | valid time = 5.08 (s) ]\n","12/30/2020 04:08:24 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 04:09:15 PM: [ train: Epoch = 18 | iter = 100/363 | loss = 0.859 | batch P@1 = 72.62 % | elapsed time = 3463.54 (s) ]\n","12/30/2020 04:10:04 PM: [ train: Epoch = 18 | iter = 200/363 | loss = 0.876 | batch P@1 = 72.73 % | elapsed time = 3513.02 (s) ]\n","12/30/2020 04:10:56 PM: [ train: Epoch = 18 | iter = 300/363 | loss = 0.862 | batch P@1 = 72.85 % | elapsed time = 3564.56 (s) ]\n","12/30/2020 04:11:28 PM: [ train: Epoch = 18 | iter = 363/363 | loss = 0.871 | batch P@1 = 72.91 % | elapsed time = 3596.53 (s) ]\n","12/30/2020 04:11:28 PM: [ train: Epoch 18 done. Time for epoch = 181.69 (s) ]\n","12/30/2020 04:11:33 PM: [ Processing candidate top-K ]\n","12/30/2020 04:11:33 PM: [ Valid (shuffled): Epoch = 18 | avg loss = 1.526 | batch P@1 = 57.93 % | P@1,100 = 43.55% | P@3,100 = 62.91% | P@10,100 = 83.18% | valid time = 5.14 (s) ]\n","12/30/2020 04:12:24 PM: [ train: Epoch = 19 | iter = 100/363 | loss = 0.806 | batch P@1 = 74.22 % | elapsed time = 3652.31 (s) ]\n","12/30/2020 04:13:14 PM: [ train: Epoch = 19 | iter = 200/363 | loss = 0.837 | batch P@1 = 74.02 % | elapsed time = 3702.14 (s) ]\n","12/30/2020 04:14:03 PM: [ train: Epoch = 19 | iter = 300/363 | loss = 0.821 | batch P@1 = 74.35 % | elapsed time = 3751.96 (s) ]\n","12/30/2020 04:14:35 PM: [ train: Epoch = 19 | iter = 363/363 | loss = 0.824 | batch P@1 = 74.29 % | elapsed time = 3783.73 (s) ]\n","12/30/2020 04:14:35 PM: [ train: Epoch 19 done. Time for epoch = 182.00 (s) ]\n","12/30/2020 04:14:40 PM: [ Processing candidate top-K ]\n","12/30/2020 04:14:40 PM: [ Valid (shuffled): Epoch = 19 | avg loss = 1.474 | batch P@1 = 60.75 % | P@1,100 = 43.55% | P@3,100 = 65.64% | P@10,100 = 85.55% | valid time = 5.12 (s) ]\n","12/30/2020 04:14:40 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 04:15:31 PM: [ train: Epoch = 20 | iter = 100/363 | loss = 0.825 | batch P@1 = 74.53 % | elapsed time = 3840.03 (s) ]\n","12/30/2020 04:16:21 PM: [ train: Epoch = 20 | iter = 200/363 | loss = 0.785 | batch P@1 = 74.72 % | elapsed time = 3889.86 (s) ]\n","12/30/2020 04:17:13 PM: [ train: Epoch = 20 | iter = 300/363 | loss = 0.782 | batch P@1 = 74.53 % | elapsed time = 3941.22 (s) ]\n","12/30/2020 04:17:45 PM: [ train: Epoch = 20 | iter = 363/363 | loss = 0.708 | batch P@1 = 75.16 % | elapsed time = 3973.96 (s) ]\n","12/30/2020 04:17:45 PM: [ train: Epoch 20 done. Time for epoch = 182.51 (s) ]\n","12/30/2020 04:17:50 PM: [ Processing candidate top-K ]\n","12/30/2020 04:17:50 PM: [ Valid (shuffled): Epoch = 20 | avg loss = 1.497 | batch P@1 = 60.07 % | P@1,100 = 43.45% | P@3,100 = 66.00% | P@10,100 = 85.36% | valid time = 4.98 (s) ]\n","12/30/2020 04:18:41 PM: [ train: Epoch = 21 | iter = 100/363 | loss = 0.742 | batch P@1 = 76.38 % | elapsed time = 4029.66 (s) ]\n","12/30/2020 04:19:32 PM: [ train: Epoch = 21 | iter = 200/363 | loss = 0.729 | batch P@1 = 76.78 % | elapsed time = 4080.37 (s) ]\n","12/30/2020 04:20:21 PM: [ train: Epoch = 21 | iter = 300/363 | loss = 0.717 | batch P@1 = 76.89 % | elapsed time = 4129.90 (s) ]\n","12/30/2020 04:20:53 PM: [ train: Epoch = 21 | iter = 363/363 | loss = 0.702 | batch P@1 = 77.03 % | elapsed time = 4161.41 (s) ]\n","12/30/2020 04:20:53 PM: [ train: Epoch 21 done. Time for epoch = 182.37 (s) ]\n","12/30/2020 04:20:58 PM: [ Processing candidate top-K ]\n","12/30/2020 04:20:58 PM: [ Valid (shuffled): Epoch = 21 | avg loss = 1.385 | batch P@1 = 62.64 % | P@1,100 = 44.09% | P@3,100 = 65.82% | P@10,100 = 85.18% | valid time = 5.10 (s) ]\n","12/30/2020 04:20:58 PM: [ New best loss, saving model to models/phobert_prepend_normalize_finetune_bosung.pt ]\n","12/30/2020 04:21:52 PM: [ train: Epoch = 22 | iter = 100/363 | loss = 0.674 | batch P@1 = 78.34 % | elapsed time = 4220.47 (s) ]\n","12/30/2020 04:22:41 PM: [ train: Epoch = 22 | iter = 200/363 | loss = 0.678 | batch P@1 = 78.38 % | elapsed time = 4269.76 (s) ]\n","12/30/2020 04:23:32 PM: [ train: Epoch = 22 | iter = 300/363 | loss = 0.688 | batch P@1 = 77.95 % | elapsed time = 4320.86 (s) ]\n","12/30/2020 04:24:04 PM: [ train: Epoch = 22 | iter = 363/363 | loss = 0.683 | batch P@1 = 77.95 % | elapsed time = 4352.07 (s) ]\n","12/30/2020 04:24:04 PM: [ train: Epoch 22 done. Time for epoch = 182.98 (s) ]\n","12/30/2020 04:24:09 PM: [ Processing candidate top-K ]\n","12/30/2020 04:24:09 PM: [ Valid (shuffled): Epoch = 22 | avg loss = 1.421 | batch P@1 = 62.38 % | P@1,100 = 45.55% | P@3,100 = 67.82% | P@10,100 = 86.18% | valid time = 5.16 (s) ]\n","12/30/2020 04:25:00 PM: [ train: Epoch = 23 | iter = 100/363 | loss = 0.651 | batch P@1 = 79.16 % | elapsed time = 4408.42 (s) ]\n","12/30/2020 04:25:49 PM: [ train: Epoch = 23 | iter = 200/363 | loss = 0.647 | batch P@1 = 79.00 % | elapsed time = 4457.68 (s) ]\n","12/30/2020 04:26:41 PM: [ train: Epoch = 23 | iter = 300/363 | loss = 0.674 | batch P@1 = 78.70 % | elapsed time = 4509.19 (s) ]\n","12/30/2020 04:27:11 PM: [ train: Epoch = 23 | iter = 363/363 | loss = 0.635 | batch P@1 = 79.02 % | elapsed time = 4539.62 (s) ]\n","12/30/2020 04:27:11 PM: [ train: Epoch 23 done. Time for epoch = 182.33 (s) ]\n","12/30/2020 04:27:16 PM: [ Processing candidate top-K ]\n","12/30/2020 04:27:16 PM: [ Valid (shuffled): Epoch = 23 | avg loss = 1.406 | batch P@1 = 62.04 % | P@1,100 = 42.91% | P@3,100 = 65.55% | P@10,100 = 85.55% | valid time = 5.14 (s) ]\n","12/30/2020 04:28:07 PM: [ train: Epoch = 24 | iter = 100/363 | loss = 0.624 | batch P@1 = 79.47 % | elapsed time = 4595.68 (s) ]\n","12/30/2020 04:28:57 PM: [ train: Epoch = 24 | iter = 200/363 | loss = 0.615 | batch P@1 = 79.36 % | elapsed time = 4645.69 (s) ]\n","12/30/2020 04:29:48 PM: [ train: Epoch = 24 | iter = 300/363 | loss = 0.610 | batch P@1 = 79.65 % | elapsed time = 4696.72 (s) ]\n","12/30/2020 04:30:20 PM: [ train: Epoch = 24 | iter = 363/363 | loss = 0.615 | batch P@1 = 79.76 % | elapsed time = 4728.64 (s) ]\n","12/30/2020 04:30:20 PM: [ train: Epoch 24 done. Time for epoch = 183.80 (s) ]\n","12/30/2020 04:30:25 PM: [ Processing candidate top-K ]\n","12/30/2020 04:30:25 PM: [ Valid (shuffled): Epoch = 24 | avg loss = 1.409 | batch P@1 = 61.70 % | P@1,100 = 46.00% | P@3,100 = 67.36% | P@10,100 = 86.00% | valid time = 5.13 (s) ]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"J3aJxoYD36aC"},"source":["# Kết quả\n"]},{"cell_type":"markdown","metadata":{"id":"o3ag_SWAjMqX"},"source":["\n","- finetune UVM old:\n"," + P@1,100 = 20.67%\n"," + BLEU = 7.08\n","\n","- prepend + finetune + UVM old\n"," + BLEU = 6.74\n"," + P@1,100 = 23.33% | P@3,100 = 50.00% | P@10,100 = 72.33%\n","\n","- normalize + finetune + UVM old\n"," + BLEU = 6.70\n"," +  P@1,100 = 21.33% | P@3,100 = 43.67% | P@10,100 = 66.00%\n","\n","\n","- Gốc, turn = 2\n"," + P@1,100 = 25.00%\n"," + BLEU = 6.19\n","\n","- Finetune + normalize:\n"," + P@1,100 = 27.00% | P@3,100 = 51.33% | P@10,100 = 77.00%\n"," + BLEU = 6.38%\n","\n","- Emo prepend, lọc ? !, turn = 2\n"," + P@1,100 = 28.33% | P@3,100 = 57.67% | P@10,100 = 82.00%\n"," + BLEU = 6.55\n","\n","- Emo prepend, turn = 4, lọc ? !, cosine - norm\n"," + P@1,100 = 31.33% | P@3,100 = 62.33% | P@10,100 = 85.00%\n"," + BLEU = 6.545\n","\n","- finetune, Emo prepend, normalize:\n"," + P@1,100 = 30.67% | P@3,100 = 59.33% | P@10,100 = 85.33%\n"," + BLEU = 6.46\n"," \n","- pretrain + Fine tuned, emo prepend, oversample, lọc ?!, dot - norm\n"," + P@1,100 = 37.67% | P@3,100 = 74.00% | P@10,100 = 91.67%\n"," + BLEU: 6.51%\n","\n","- pretrain + Fine tuned, emo prepend, oversample, lọc ?!, dot - norm, evaluate turn = 1\n"," + P@1,100 = 41.33% | P@3,100 = 66.67% | P@10,100 = 84.33%\n"," + BLEU: 6.22%\n"," \n","- pretrain + Fine tuned, emo prepend, oversample, lọc ?!\n"," + P@1,100 = 38.67% | P@3,100 = 77.67% | P@10,100 = 92.67%\n"," + BLEU = 5.82%\n","\n","- pretrain UVA, emotion prepend, normalize\n"," + P@1,100 = 36.67% | P@3,100 = 73.33% | P@10,100 = 92.33%\n"," + BLEU = 6.42\n","\n","- pretrain, finetuned bosung, emotion prepend, normalize\n"," + P@1,100 = 37.67% | P@3,100 = 72.00% | P@10,100 = 93.00%\n"," + BLEU = 6.37%\n","- finetuned bosung, emotion prepend, normalize\n"," + P@1,100 = 31.33% | P@3,100 = 62.67% | P@10,100 = 85.67%\n"," + BLEU = 6.23"]},{"cell_type":"markdown","metadata":{"id":"Sy40YBzPwsRX"},"source":["# Demo"]},{"cell_type":"code","metadata":{"id":"I34f5LtNAdAu"},"source":["net = Net(device, False)\n","\n","if device == \"cuda\":\n","  torch.cuda.set_device(-1) # get the lastest device (GPU)\n","  net = torch.nn.DataParallel(net)\n","  net.cuda()\n","  \n","net.load_state_dict(torch.load(option.model_file), strict = False)\n","# net.load_state_dict(torch.load(\"models/phobert_auto.pt\"), strict = False)\n","net.eval()\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KURPVKBrAmFp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425413918,"user_tz":-420,"elapsed":100554,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"efd96b1b-1a88-46b6-e26f-b82596ba631e"},"source":["import time\n","start_time = time.time()\n","\n","all_cands = []\n","\n","with torch.no_grad():\n","    for i, ex in enumerate(train_iter):\n","        batch_size = ex[0].size(0)\n","        params = [\n","            field\n","            if field is not None\n","            else None\n","            for field in ex\n","        ]\n","            \n","        cands = net(params[1][:,0,:])\n","        all_cands.append(cands)\n","\n","    all_cands = torch.cat(all_cands, dim = 0)\n","\n","\n","end_time = time.time()\n","print(\"Total time load candidates: \", end_time - start_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Total time load candidates:  15.854732751846313\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OKr3ZsEz8Tq6"},"source":["torch.save(all_cands, \"torch_pre_load/all_cands_prepend_normalize_manual_bosung.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cvgLqb-bBHJJ"},"source":["# all_cands = torch.load(\"torch_pre_load/all_cands_finetuned_normalize.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w86P7wheGF49"},"source":["def predict(context, top_n=5, normalize=True):\n","    \"\"\"\n","    returns a list of top_n tuples (\"sentence\", \"score\")\n","    \"\"\"\n","  \n","    all_input_ids = txt2vec(context, 256)\n","    with torch.no_grad():\n","        if device == \"cuda\":\n","            all_input_ids = all_input_ids.cuda(non_blocking=True)\n","       \n","        ctx = net(all_input_ids)\n","        scores, index = score_candidates(ctx, all_cands, top_n, normalize)\n","        response = []\n","        for i, (score, index) in enumerate(zip(scores.squeeze(0), index.squeeze(0)), 1):\n","            response.append((train_dataset[index], float(score)))\n","     \n","        return response"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dX-AKolAAqDX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609382700962,"user_tz":-420,"elapsed":51987,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"b117f840-6c43-4d50-9a2a-91419f64c0de"},"source":["sentence = \"bà tôi vừa qua đời\"\n","outs = predict(sentence, top_n = 10, normalize = option.normalize)\n","for item in outs:\n","    print(\"Score: \", item[1], \"\\nResponse: \",  str.format(\"{}\",tokenizer.decode(item[0][1][0][2:-1]).replace(\"_\", \" \")))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Score:  7.895349979400635 \n","Response:  tôi rất tiếc khi nghe điều đó. bà tôi cũng mất gần đây.\n","Score:  7.838269233703613 \n","Response:  rất tiếc khi biết điều đó. bây giờ tôi chỉ còn lại mình bà thôi. ông tôi đã qua 1 tháng trước\n","Score:  7.703534126281738 \n","Response:  tôi rất tiếc khi nghe điều đó. bạn đã dành nhiều thời gian bên bà không?\n","Score:  7.218474864959717 \n","Response:  buồn vậy. bà mất vì bệnh hay vì tuổi cao?\n","Score:  7.198681831359863 \n","Response:  tôi bà đã không còn sống với bạn nữa?\n","Score:  7.1826653480529785 \n","Response:  tôi rất tiếc khi nghe điều đó. tôi hy vọng bà ấy sẽ sớm bình phục.\n","Score:  7.066975116729736 \n","Response:  tôi rất tiếc khi nghe điều đó. bà mới qua đời gần đây sao?\n","Score:  7.053089141845703 \n","Response:  gần đây tôi đã mất bà tôi. tôi nghĩ rằng tôi sẽ không vượt qua được.\n","Score:  6.938544273376465 \n","Response:  điều đó thật tệ. tôi yêu mẹ tôi rất nhiều, tôi không thể tưởng tượng được rằng mẹ đã mất...\n","Score:  6.854318618774414 \n","Response:  tôi xin chia buồn cùng anh, tôi cũng đã mất bà tôi vì căn bệnh ung thư, và chuyện biết trước bà sẽ mất cũng không làm mọi thứ tốt hơn.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xuhP_-3jDq8Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605495415847,"user_tz":-420,"elapsed":1273,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"91fcc827-a0e7-45a3-9d6c-6c3712a226f0"},"source":["index = 230\n","\n","print(\"Sentence: \", tokenizer.decode(train_dataset[index][0][0]))\n","print(\"Target: \", tokenizer.decode(train_dataset[index][1][0]))\n","\n","print(10*\"*\")\n","\n","outs = predict(tokenizer.decode(train_dataset[index][0][0]), 10, normalize = option.normalize)\n","for item in outs:\n","    print(\"Score: \", item[1], \"\\nResponse: \",  str.format(\"{}\", tokenizer.decode(item[0][1][0][2:-1])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence:  <s> tôi đang cắt cỏ trong vườn, có cục đá bay vào nhà hàng_xóm làm bễ kiếng của sổ của họ. </s>\n","Target:  <s> 6 ôi không … rồi có chuyện gì không? </s>\n","**********\n","Score:  7.315635681152344 \n","Response:  ôi, nghe thật kinh_khủng! nó có phải đồ_hoạ không?\n","Score:  7.296921730041504 \n","Response:  bất_ngờ nha. một cái lỗ dưới hàng_rào ư? tôi rất tiếc khi nghe điều đó.\n","Score:  7.146152019500732 \n","Response:  haha. đôi_khi nó trông có_vẻ như_vậy đấy. chúng có_thể đậu ở những nơi khuất mãi_mãi và chỉ di_chuyển vào giấy cuối_cùng khi bạn vung cái vợt đập ruồi thôi. gioongs như seal team six hay_là những thứ giống vậy.\n","Score:  6.83128547668457 \n","Response:  lấy chai xịt hot shots hoặc raid spray, phun từ khoảng 6 đến 9 mét vào không_trung. tôi phun tất_cả mọi nơi từ mặt_đất đến mái nhà của tôi. phun và chạy. lol\n","Score:  6.7333197593688965 \n","Response:  nghe có_vẻ đau_đớn. tôi sẽ đổ rác trước toà thị_chính.\n","Score:  6.729208469390869 \n","Response:  trời! em ghét chuyện giống như_vậy và em cá là nó làm người ta hoảng vì nhìn như_ai đó đã đột_nhập vào nhà vậy. nhưng giờ chị cũng đã cho người sửa lại rồi. chuyện xui ha.\n","Score:  6.665366172790527 \n","Response:  tôi nhớ hồi tôi còn nhỏ có nhiều người ném thức_ăn lên trời và xem chúng có bắt được không.\n","Score:  6.644867897033691 \n","Response:  điều đó thực_sự đáng sợ! tôi hy_vọng bạn đã đánh_bại con quái_vật đó bằng một chiếc đĩa ruồi lớn nhất hiện có.\n","Score:  6.461124420166016 \n","Response:  haha điều đó thì khá buồn_cười đấy chứ\n","Score:  6.4478068351745605 \n","Response:  ôi con mèo tội_nghiệp! mà đó là lỗi của hàng_xóm bạn chắc luôn rồi. bạn đã nói cho họ nghe về điều đó chưa? với cả bạn có_thể mua mấy cái vòi xịt gì đấy để ngăn cho lũ mèo không vào vườn của mình. nó sẽ phun nước khi có bất_kì con mèo nào vượt qua cái hàng_rào.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nJs2TvI8wtW_"},"source":["# Evaluate for test set"]},{"cell_type":"markdown","metadata":{"id":"vKWdAE2DEJKw"},"source":["## P@1,100"]},{"cell_type":"code","metadata":{"id":"gwDFK9yXAwL5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609425417139,"user_tz":-420,"elapsed":3209,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"e2d2ff3a-2a8d-4a08-9be1-695736d943a0"},"source":["test_dataset = EmpDataset(\n","#   \"ED/test_manual_compound\",\n","  \"ED/test_manual\",\n","  maxlen = max_tokens_length,\n","  history_len = option.max_turn,\n","  prepend = option.prepend,\n","  over_sample = False\n",")\n","\n","sh_test_iter = DataLoader(\n","  dataset     = test_dataset,\n","  batch_size  = option.batch_size,\n","  shuffle     = True,\n","  num_workers = 0,\n","  collate_fn  = batchify,\n","  pin_memory  = True,\n",")\n","\n","un_test_iter = DataLoader(\n","  dataset     = test_dataset,\n","  batch_size  = option.batch_size,\n","  shuffle     = False,\n","  num_workers = 0,\n","  collate_fn  = batchify,\n","  pin_memory  = True,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 694/694 [00:02<00:00, 336.11it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QfiNHzEaAzhX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609382715713,"user_tz":-420,"elapsed":4160,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"39e0660e-5e7d-4938-b231-be69dfaac3ec"},"source":["with torch.no_grad():\n","  validate(\n","    0,\n","    net,\n","    sh_test_iter,\n","    shuffle = True,\n","    nb_candidates = option.hits_at_nb_cands,\n","    normalize = option.normalize\n","  )\n","\n","with torch.no_grad():\n","  validate(\n","    0,\n","    net,\n","    un_test_iter,\n","    shuffle = False, \n","    nb_candidates= option.hits_at_nb_cands,\n","  )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["12/31/2020 02:45:14 AM: [ Processing candidate top-K ]\n","12/31/2020 02:45:14 AM: [ Valid (True): Epoch = 0 | avg loss = 1.458 | batch P@1 = 58.46 % | P@1,100 = 40.67% | P@3,100 = 61.00% | P@10,100 = 85.67% | valid time = 1.48 (s) ]\n","12/31/2020 02:45:16 AM: [ Processing candidate top-K ]\n","12/31/2020 02:45:16 AM: [ Valid (False): Epoch = 0 | avg loss = 2.375 | batch P@1 = 40.31 % | P@1,100 = 31.67% | P@3,100 = 63.00% | P@10,100 = 85.67% | valid time = 1.39 (s) ]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"77rZDF7mD1YG"},"source":["## BLEU"]},{"cell_type":"code","metadata":{"id":"uR89LOD1Vkum"},"source":["# Lọc 3 token ở đầu thừa trước khi tính BLEU\n","filter = 2 # <s> and <emo>\n","\n","for i in range(len(test_dataset)):\n","    test_dataset[i][1] = test_dataset[i][1][:,filter:]\n","\n","un_test_iter = DataLoader(\n","  dataset     = test_dataset,\n","  batch_size  = option.batch_size,\n","  shuffle     = False,\n","  num_workers = 0,\n","  collate_fn  = batchify,\n","  pin_memory  = True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3644R07hFO5j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609382717115,"user_tz":-420,"elapsed":2973,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"567bc23a-9f56-4569-ce7d-b71d6401b74f"},"source":["# from fairseq import bleu # version 0.9.0\n","from fairseq.scoring import bleu # version 0.10.0\n","\n","def BLEU_calculate(data_loader, top_n=5, normalize=True):\n","    scorer = bleu.Scorer(pad_idx, tokenizer.eos_token_id, tokenizer.unk_token_id)\n","    with torch.no_grad():\n","        for i, ex in enumerate(data_loader):\n","            batch_size = ex[0].size(0)\n","            params = [\n","                field\n","                if field is not None\n","                else None\n","                for field in ex\n","            ]\n","    \n","            ctx = net(params[0][:,0,:])\n","            cands =   params[1][:,0,:]\n","             \n","            _, index = score_candidates(ctx, all_cands, top_n, normalize)\n","            index = index[:,0].cpu()\n","            predicts = []\n","         \n","            #BLEU calculate\n","            for i in range(batch_size):\n","              scorer.add(\n","                  cands[i].type(torch.IntTensor),  \n","                  train_dataset[index[i]][1][:,filter:].type(torch.IntTensor)\n","              )\n","\n","    def get_float(result):\n","      return float(result.split(',')[0].split(\"=\")[-1])\n","\n","    return (\n","        get_float(scorer.result_string(order=4))+\n","        get_float(scorer.result_string(order=3))+\n","        get_float(scorer.result_string(order=2))+\n","        get_float(scorer.result_string(order=1))\n","    )/4\n","\n","print(str.format(\"BLEU: {:.2f}%\", BLEU_calculate(un_test_iter, normalize = option.normalize)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BLEU: 6.22%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r050vPKJ1RRY"},"source":["# test"]},{"cell_type":"code","metadata":{"id":"2upfyUaecNdA"},"source":["pip install gradio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ds47rlYTP1oD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604493567293,"user_tz":-420,"elapsed":1145,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"fd5029ae-c526-4b0c-b4b3-4fa34c7c7b5b"},"source":["def clean_answer(outs):\n","  rs = []\n","  for item in outs:\n","    rs.append(tokenizer.decode(item[0][1][0][2:-1]).replace(\"_\", \" \"))\n","  return \"\\n\".join(rs)\n","\n","def greet(sentence):\n","  outs = predict(net, sentence, 2)\n","  return clean_answer(outs)\n","\n"," "],"execution_count":null,"outputs":[{"output_type":"stream","text":["mặt tốt là, nó sẽ có thể là một lý do tuyệt vời để đặt bánh pizza.\n","đó chính là tất cả những gì về lễ tạ ơn lol\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4tc57DracRD1"},"source":["import gradio as gr\n","\n","def clean_answer(outs):\n","  rs = []\n","  for item in outs:\n","    rs.append(tokenizer.decode(item[0][1][0][3:-1]).replace(\"_\", \" \"))\n","  return \"\\n\".join(rs)\n","\n","def greet(sentence):\n","  outs = predict(net, sentence, 1)\n","  return clean_answer(outs)\n","\n","iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n","iface.launch(debug=True, share=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fh_PXHZ94C6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605150568083,"user_tz":-420,"elapsed":6249,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"4235e413-8c64-4e50-e222-be5fcc8e1a42"},"source":["with torch.no_grad():\n","  validate(\n","    0,\n","    net,\n","    dev_iter,\n","    shuffle = False, \n","    nb_candidates= option.hits_at_nb_cands,\n","  )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["11/12/2020 03:09:28 AM: [ Processing candidate top-K ]\n","11/12/2020 03:09:28 AM: [ Valid (False): Epoch = 0 | avg loss = 2.830 | batch P@1 = 34.62 % | P@1,100 = 26.27% | P@3,100 = 57.18% | P@10,100 = 79.91% | valid time = 4.87 (s) ]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GVgusw2pbdKI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605445179430,"user_tz":-420,"elapsed":695,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"876eba9c-d7b2-4f1e-d30f-05294f975cfc"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sun Nov 15 12:59:39 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    33W / 250W |  16277MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y5woa_XzH0-_"},"source":["# Googletrans"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":544},"id":"uPSJR0v2a9G0","executionInfo":{"status":"ok","timestamp":1608388937976,"user_tz":-420,"elapsed":3633,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"bd8432a7-eb3c-426a-9e2e-d2e332276799"},"source":["!pip install googletrans==3.1.0a0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting googletrans==3.1.0a0\n","  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n","Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.6/dist-packages (from googletrans==3.1.0a0) (0.13.3)\n","Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.4.0)\n","Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n","Requirement already satisfied: hstspreload in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.11.21)\n","Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n","Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n","Requirement already satisfied: contextvars>=2.1; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from sniffio->httpx==0.13.3->googletrans==3.1.0a0) (2.4)\n","Requirement already satisfied: h2==3.* in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n","Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n","Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.1; python_version < \"3.7\"->sniffio->httpx==0.13.3->googletrans==3.1.0a0) (0.14)\n","Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n","Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n","Building wheels for collected packages: googletrans\n","  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp36-none-any.whl size=16368 sha256=d3645b15f823da2ec4e870f1c081c480414f97bfec52165c4f3d4c7c0251b20b\n","  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n","Successfully built googletrans\n","Installing collected packages: googletrans\n","  Found existing installation: googletrans 3.0.0\n","    Uninstalling googletrans-3.0.0:\n","      Successfully uninstalled googletrans-3.0.0\n","Successfully installed googletrans-3.1.0a0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["googletrans"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"o0HWR7-ca9xw","executionInfo":{"status":"ok","timestamp":1608389115013,"user_tz":-420,"elapsed":857,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"a8ccdf27-f6bf-4381-d587-9637ab46866f"},"source":["from googletrans import Translator\r\n","translator = Translator()\r\n","\r\n","translator.translate(translator.translate('mẹ thấy con tệ quá', dest='en').text, dest=\"vi\").text\r\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tôi nghĩ bạn thật tệ'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7S0X8K6Pj1p","executionInfo":{"status":"ok","timestamp":1609425648649,"user_tz":-420,"elapsed":702,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"a998e53e-40f0-4169-efd3-be173f46e35d"},"source":["\r\n","class TextData(data.Dataset):\r\n","    def __init__(\r\n","        self,\r\n","        splitname,\r\n","        maxlen=256,  # max number of tokens per sentence\r\n","        history_len=2,\r\n","        prepend=True,  # add label as prefix\r\n","        over_sample=False\r\n","    ):\r\n","\r\n","        df = open(f\"{splitname}.csv\", \"r\", encoding=\"utf-8\").readlines()\r\n","        self.max_hist_len = history_len * 2 - 1\r\n","        self.data = []\r\n","        history = []\r\n","        for i in tqdm(range(1, len(df))):\r\n","\r\n","            cparts = df[i - 1].strip().split(\",\")\r\n","            sparts = df[i].strip().split(\",\")\r\n","            if cparts[0] == sparts[0]:\r\n","\r\n","                history.append(preprocess(cparts[5]))\r\n","                idx = int(sparts[1])\r\n","                if (idx % 2) == 0:\r\n","                    # Lay cac turn cuoi\r\n","                    # SOC start of comment\r\n","                    sentence2 = preprocess(sparts[5])\r\n","\r\n","                    if over_sample:\r\n","                        history[-1] = history[-1].replace(\r\n","                            \"?\", \"\").replace(\"!\", \"\").strip()\r\n","                        # if(len(history) == 1):\r\n","                        self.data.append([history[-1], sentence2, sparts[2]])\r\n","                        sentence1 = \" | \".join(history[-self.max_hist_len:])\r\n","                        if(len(history) != 1):\r\n","                            self.data.append([sentence1, sentence2, sparts[2]])\r\n","\r\n","                    else:\r\n","                        history[-1] = history[-1].replace(\r\n","                            \"?\", \"\").replace(\"!\", \"\").strip()\r\n","                        sentence1 = \" | \".join(history[-self.max_hist_len:])\r\n","                        self.data.append([sentence1, sentence2, sparts[2]])\r\n","            else:\r\n","                history = []\r\n","\r\n","    def __len__(self):\r\n","        return len(self.data)\r\n","\r\n","    def __getitem__(self, index):\r\n","        return self.data[index]\r\n","\r\n","\r\n","test_dataset = TextData(\r\n","    \"ED/test_manual\",\r\n","    maxlen=max_tokens_length,\r\n","    history_len=option.max_turn,\r\n","    prepend=option.prepend,\r\n","    over_sample=option.train and option.over_sample\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 694/694 [00:00<00:00, 60648.96it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kIo0PftATxDC"},"source":["# excited, scared, angry, sad, neutral\r\n","all_emotions_cls = [\r\n","    [\r\n","        \"confident\",\r\n","        \"impressed\",\r\n","        \"joyful\",\r\n","        \"faithful\",\r\n","        \"excited\",\r\n","        \"grateful\",\r\n","        \"prepared\",\r\n","        \"hopeful\",\r\n","        \"proud\",\r\n","        \"content\",\r\n","        \"surprised\",\r\n","        \"caring\",\r\n","        \"trusting\",\r\n","        \"anticipating\",\r\n","    ],\r\n","    [\r\n","        \"afraid\",\r\n","        \"ashamed\",\r\n","        \"anxious\",\r\n","        \"guilty\",\r\n","        \"apprehensive\",\r\n","        \"embarrassed\",\r\n","    ],\r\n","    [\r\n","        \"jealous\",\r\n","        \"disgusted\",\r\n","        \"angry\",\r\n","        \"annoyed\",\r\n","        \"furious\",\r\n","    ],\r\n","    [\r\n","        \"disappointed\",\r\n","        \"sad\",\r\n","        \"lonely\",\r\n","        \"devastated\",\r\n","        \"terrified\",\r\n","    ],\r\n","    [\r\n","        \"sentimental\",\r\n","        \"nostalgic\"\r\n","    ]\r\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yS58wv_VT5CR"},"source":["\r\n","# excited, scared, angry, sad, neutral\r\n","def check_emo(emo):\r\n","    if emo in all_emotions_cls[0]:\r\n","        return \"excited\"\r\n","\r\n","    if emo in all_emotions_cls[1]:\r\n","        return \"scared\" \r\n","\r\n","    if emo in all_emotions_cls[2]:\r\n","        return \"angry\" \r\n","    if emo in all_emotions_cls[3]:\r\n","        return \"sad\" \r\n","    if emo in all_emotions_cls[4]:\r\n","        return \"neutral\" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRBRCcahO7Ea"},"source":["with open(\"danhgia_duytridoithoai.csv\", \"w\", encoding=\"utf-8\") as f:\r\n","    f.write(\"Câu gốc, Ground truth, Dự đoán\\n\")\r\n","    for i in test_dataset:\r\n","        # print(i[0], \"\\nground truth: \", i[2])\r\n","        outs = predict(i[0], top_n = 1, normalize = option.normalize)\r\n","        item = outs[0]\r\n","        indx = int(tokenizer.decode(item[0][1][0][1:2]))\r\n","        f.write(str.format(\"{},{},{}\\n\", i[0].replace(\",\", \"_comma_\"), check_emo(i[2]), check_emo(lbEnc.classes_[indx])))\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyD4fbwoO7fC","executionInfo":{"status":"ok","timestamp":1609425962190,"user_tz":-420,"elapsed":659,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"bd641f06-2dcc-4032-8926-7b975d10c540"},"source":["lbEnc.classes_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['afraid', 'angry', 'annoyed', 'anticipating', 'anxious',\n","       'apprehensive', 'ashamed', 'caring', 'confident', 'content',\n","       'devastated', 'disappointed', 'disgusted', 'embarrassed',\n","       'excited', 'faithful', 'furious', 'grateful', 'guilty', 'hopeful',\n","       'impressed', 'jealous', 'joyful', 'lonely', 'nostalgic',\n","       'prepared', 'proud', 'sad', 'sentimental', 'surprised',\n","       'terrified', 'trusting'], dtype='<U12')"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LJ50vXLYQcUd","executionInfo":{"status":"ok","timestamp":1609425992662,"user_tz":-420,"elapsed":1143,"user":{"displayName":"Đặng Quốc Tiến","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj4VmITHI4Ij_PQ9Q-Fw9RKGJls-GuKHqcuczTP=s64","userId":"17395221261139329256"}},"outputId":"ce6b5029-2690-407e-cbe3-f1e526fc21dd"},"source":["lbEnc.transform(lbEnc.classes_)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"PP5bYurkQmd5"},"source":["i = test_dataset[5]\r\n","print(i[0], \"\\nground truth: \", i[2])\r\n","outs = predict(i[0], top_n = 10, normalize = option.normalize)\r\n","item = outs[0]\r\n","indx = int(tokenizer.decode(item[0][1][0][1:2]))\r\n","print(\"out: \", lbEnc.classes_[indx])"],"execution_count":null,"outputs":[]}]}